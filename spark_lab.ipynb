{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark\n",
    "# pip install findspark \n",
    "# pip show pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac81968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/05 09:18:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#import findspark\n",
    "#findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"lab\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d5d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,column,expr,lit\n",
    "from pyspark.sql import Row \n",
    "from pyspark.sql.types import StructType,StructField,StringType,LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e327ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Spark (in Python or R), there is no such thing as a Dataset. Everything is a DataFrame \n",
    "spark.range(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.range(2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "        .format(\"json\") \\\n",
    "        .load(\"/Applications/MAMP/htdocs/Spark-The-Definitive-Guide/data/flight-data/json/2015-summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5665ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825dc735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d11ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfRowObjects = df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(listOfRowObjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba280a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listOfRowObjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(listOfRowObjects[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(1, (2,2))], [\"a\", \"b\"])\n",
    "df.show()\n",
    "df.printSchema(1)\n",
    "df.printSchema(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91be883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6525b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,column,expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd6f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df.a).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df['a']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(col('a')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An expression created via the `expr` function is just a DataFrame column reference\n",
    "# In the simplest case, expr(\"someCol\") is equivalent to col(\"someCol\")\n",
    "expr('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d09a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the below are same! \n",
    "print(expr('a - 5'))\n",
    "print(col('a') - 5)\n",
    "print(expr('a') -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49084efc",
   "metadata": {},
   "source": [
    "### Records and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464911b",
   "metadata": {},
   "source": [
    "### Creating Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row \n",
    "myRow = Row(\"Hello\", None, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7be70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf104cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from dfTable\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04394e42",
   "metadata": {},
   "source": [
    "### Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType,StructField,StringType,LongType\n",
    "myManualSchema = StructType([\n",
    "    StructField('first_name', StringType(), True),\n",
    "    StructField('last_name', StringType(), True),\n",
    "    StructField('age', LongType(), True)\n",
    "])\n",
    "\n",
    "alice = Row(\"Alice\", \"Henderson\", 25)\n",
    "bob = Row(\"Bob\", \"Sanders\", 28)\n",
    "spark.createDataFrame([alice, bob], myManualSchema).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sparksql-magic\n",
    "# Load the extension\n",
    "%load_ext sparksql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe82afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "select * from dfTable limit 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6c8bc",
   "metadata": {},
   "source": [
    "### select and selectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME').show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcae09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col, column\n",
    "df.select(\n",
    "    expr('DEST_COUNTRY_NAME'),\n",
    "    col('DEST_COUNTRY_NAME'),\n",
    "    column('DEST_COUNTRY_NAME')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda59b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(col('DEST_COUNTRY_NAME'), 'DEST_COUNTRY_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr('DEST_COUNTRY_NAME as destination')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr('DEST_COUNTRY_NAME as destination').alias('alias_destination')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02665a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr('DEST_COUNTRY_NAME as destination', 'DEST_COUNTRY_NAME').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3689037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr('*', '(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withInCountry').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b33441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation over the entire DataFrame\n",
    "df.selectExpr('avg(count)','count(distinct(DEST_COUNTRY_NAME))').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2072dc",
   "metadata": {},
   "source": [
    "### Converting to Spark Types (Literals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.select('*',lit(1).alias('one')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72528fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr('*'),lit(1).alias('one')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65bfbd",
   "metadata": {},
   "source": [
    "### Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn('one', lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932be236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to add a column!\n",
    "df.withColumn('withInCountry', expr('DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c687f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to rename a column!\n",
    "df.withColumn('destination',expr('DEST_COUNTRY_NAME')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7fd48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumnRenamed('DEST_COUNTRY_NAME','destination').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName = df.withColumn('Col Name With Space',expr('DEST_COUNTRY_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName.selectExpr('`Col Name With Space`', '`Col Name With Space` as `new col`').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f298fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName.select(col('Col Name With Space')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to escape expressions that use reserved characters/keywords\n",
    "dfWithLongColName.select(expr('`Col Name With Space`')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666dc714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn('count2', col('count').cast('int')).printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.filter(col('count') < 2).show(2)\n",
    "# df.filter(expr('count') < 2).show(2)\n",
    "df.filter(expr('count < 2')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where('count < 2').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(col('count') < 2).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(col('count') < 2)\\\n",
    "    .where(\"ORIGIN_COUNTRY_NAME != 'Croatia'\")\\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(col('count') < 2).where(col('ORIGIN_COUNTRY_NAME') != 'Croatia').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('DEST_COUNTRY_NAME','ORIGIN_COUNTRY_NAME').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac20adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('ORIGIN_COUNTRY_NAME').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafbcc7",
   "metadata": {},
   "source": [
    "### Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0247248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling without replacement, in which a subset of the observations is selected randomly, and once an observation is selected it cannot be selected again. \n",
    "# sampling with replacement, in which a subset of observations are selected randomly, and an observation may be selected more than once.\n",
    "df.sample(False,.9).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94364784",
   "metadata": {},
   "source": [
    "### Concatenating and Appending Rows (Union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4015e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "lastRow = Row('New Country', 'New Country', 1)\n",
    "newDF = spark.createDataFrame([lastRow], df.schema)\n",
    "df.union(newDF).where('DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME').show(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417feff5",
   "metadata": {},
   "source": [
    "### Sorting Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979bde91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort('count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6aa674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy('count','DEST_COUNTRY_NAME').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47284af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(col('count'), col('DEST_COUNTRY_NAME')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(expr('count desc')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ed33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(col('count').desc(), col('DEST_COUNTRY_NAME').asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89aed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For optimization purposes, it's sometimes advisable to sort within each partition before\n",
    "# another set of transformations\n",
    "spark.read \\\n",
    "        .format(\"json\") \\\n",
    "        .load(\"/Applications/MAMP/htdocs/Spark-The-Definitive-Guide/data/flight-data/json/*-summary.json\")\\\n",
    "        .sortWithinPartitions('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c6a7c",
   "metadata": {},
   "source": [
    "### Repartition & Coalesce\n",
    "#### https://mrpowers.medium.com/managing-spark-partitions-with-coalesce-and-repartition-4050c57ad5c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22155780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53458d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangeDF=spark.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd33891",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangeDF.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90991a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangeDF.write.csv('/Users/deepakagrawal/Desktop/data', 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "increasedPartitionedDF=rangeDF.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93441b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "increasedPartitionedDF.write.csv('/Users/deepakagrawal/Desktop/data', 'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25fd77a",
   "metadata": {},
   "source": [
    "## Chapter 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee97f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.read.format('csv') \\\n",
    "          .option('header', 'true') \\\n",
    "          .option('inferSchema','true') \\\n",
    "          .load(\"/Applications/MAMP/htdocs/Spark-The-Definitive-Guide/data/retail-data/by-day/2010-12-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a755eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d395611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('dfTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32937874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |2010-12-01 08:26:00|2.75     |17850.0   |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |22752    |SET 7 BABUSHKA NESTING BOXES       |2       |2010-12-01 08:26:00|7.65     |17850.0   |United Kingdom|\n",
      "|536365   |21730    |GLASS STAR FROSTED T-LIGHT HOLDER  |6       |2010-12-01 08:26:00|4.25     |17850.0   |United Kingdom|\n",
      "|536366   |22633    |HAND WARMER UNION JACK             |6       |2010-12-01 08:28:00|1.85     |17850.0   |United Kingdom|\n",
      "|536366   |22632    |HAND WARMER RED POLKA DOT          |6       |2010-12-01 08:28:00|1.85     |17850.0   |United Kingdom|\n",
      "|536367   |84879    |ASSORTED COLOUR BIRD ORNAMENT      |32      |2010-12-01 08:34:00|1.69     |13047.0   |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43fc3a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 5: integer (nullable = false)\n",
      " |-- five: string (nullable = false)\n",
      " |-- 5.0: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(lit(5), lit(\"five\"), lit(5.0)).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cea171cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(lit(5), lit(\"five\"), lit(5.0)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2eaf9eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'first_name'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit('first_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c38a9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'first_name'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col('first_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "535f424f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'first_name'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column('first_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08917d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'first_name'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr('first_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b63662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
