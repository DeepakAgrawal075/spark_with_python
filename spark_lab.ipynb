{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark\n",
    "# pip install findspark \n",
    "# pip show pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac81968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "#findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"lab\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e327ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Spark (in Python or R), there is no such thing as a Dataset. Everything is a DataFrame \n",
    "spark.range(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.range(2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "        .format(\"json\") \\\n",
    "        .load(\"/Applications/MAMP/htdocs/Spark-The-Definitive-Guide/data/flight-data/json/2015-summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5665ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825dc735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d11ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfRowObjects = df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(listOfRowObjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba280a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listOfRowObjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(listOfRowObjects[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(1, (2,2))], [\"a\", \"b\"])\n",
    "df.show()\n",
    "df.printSchema(1)\n",
    "df.printSchema(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6525b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,column,expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15f677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37288b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df.a).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df['a']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(col('a')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An expression created via the `expr` function is just a DataFrame column reference\n",
    "# In the simplest case, expr(\"someCol\") is equivalent to col(\"someCol\")\n",
    "expr('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the below are same! \n",
    "print(expr('a - 5'))\n",
    "print(col('a') - 5)\n",
    "print(expr('a') -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66027ad",
   "metadata": {},
   "source": [
    "### Records and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a50a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1996c4",
   "metadata": {},
   "source": [
    "### Creating Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row \n",
    "myRow = Row(\"Hello\", None, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539dcbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from dfTable\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08dc2a",
   "metadata": {},
   "source": [
    "### Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6becf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType,StructField,StringType,LongType\n",
    "myManualSchema = StructType([\n",
    "    StructField('first_name', StringType(), True),\n",
    "    StructField('last_name', StringType(), True),\n",
    "    StructField('age', LongType(), True)\n",
    "])\n",
    "\n",
    "alice = Row(\"Alice\", \"Henderson\", 25)\n",
    "bob = Row(\"Bob\", \"Sanders\", 28)\n",
    "spark.createDataFrame([alice, bob], myManualSchema).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sparksql-magic\n",
    "# Load the extension\n",
    "%load_ext sparksql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "select * from dfTable limit 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c1e76",
   "metadata": {},
   "source": [
    "### select and selectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME').show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col, column\n",
    "df.select(\n",
    "    expr('DEST_COUNTRY_NAME'),\n",
    "    col('DEST_COUNTRY_NAME'),\n",
    "    column('DEST_COUNTRY_NAME')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(col('DEST_COUNTRY_NAME'), 'DEST_COUNTRY_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558306d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr('DEST_COUNTRY_NAME as destination')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr('DEST_COUNTRY_NAME as destination').alias('alias_destination')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr('DEST_COUNTRY_NAME as destination', 'DEST_COUNTRY_NAME').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr('*', '(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withInCountry').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88138716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation over the entire DataFrame\n",
    "df.selectExpr('avg(count)','count(distinct(DEST_COUNTRY_NAME))').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0f5d5",
   "metadata": {},
   "source": [
    "### Converting to Spark Types (Literals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f3b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.select('*',lit(1).alias('one')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr('*'),lit(1).alias('one')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615fdfd",
   "metadata": {},
   "source": [
    "### Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cad901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn('one', lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to add a column!\n",
    "df.withColumn('withInCountry', expr('DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ca45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to rename a column!\n",
    "df.withColumn('destination',expr('DEST_COUNTRY_NAME')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdc330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumnRenamed('DEST_COUNTRY_NAME','destination').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ac879",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName = df.withColumn('Col Name With Space',expr('DEST_COUNTRY_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d33e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName.selectExpr('`Col Name With Space`', '`Col Name With Space` as `new col`').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName.select(col('Col Name With Space')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to escape expressions that use reserved characters/keywords\n",
    "dfWithLongColName.select(expr('`Col Name With Space`')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe397eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn('count2', col('count').cast('int')).printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b1785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.filter(col('count') < 2).show(2)\n",
    "# df.filter(expr('count') < 2).show(2)\n",
    "df.filter(expr('count < 2')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where('count < 2').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3127ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(col('count') < 2).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67080f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(col('count') < 2)\\\n",
    "    .where(\"ORIGIN_COUNTRY_NAME != 'Croatia'\")\\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3209c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(col('count') < 2).where(col('ORIGIN_COUNTRY_NAME') != 'Croatia').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('DEST_COUNTRY_NAME','ORIGIN_COUNTRY_NAME').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('ORIGIN_COUNTRY_NAME').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c8fc1",
   "metadata": {},
   "source": [
    "### Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07884b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling without replacement, in which a subset of the observations is selected randomly, and once an observation is selected it cannot be selected again. \n",
    "# sampling with replacement, in which a subset of observations are selected randomly, and an observation may be selected more than once.\n",
    "df.sample(False,.9).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb97721",
   "metadata": {},
   "source": [
    "### Concatenating and Appending Rows (Union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad403f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "lastRow = Row('New Country', 'New Country', 1)\n",
    "newDF = spark.createDataFrame([lastRow], df.schema)\n",
    "df.union(newDF).where('DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME').show(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f9a2b9",
   "metadata": {},
   "source": [
    "### Sorting Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort('count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fd59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy('count','DEST_COUNTRY_NAME').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(col('count'), col('DEST_COUNTRY_NAME')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(expr('count desc')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9028a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(col('count').desc(), col('DEST_COUNTRY_NAME').asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For optimization purposes, it's sometimes advisable to sort within each partition before\n",
    "# another set of transformations\n",
    "spark.read \\\n",
    "        .format(\"json\") \\\n",
    "        .load(\"/Applications/MAMP/htdocs/Spark-The-Definitive-Guide/data/flight-data/json/*-summary.json\")\\\n",
    "        .sortWithinPartitions('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f51c21",
   "metadata": {},
   "source": [
    "### Repartition & Coalesce\n",
    "#### https://mrpowers.medium.com/managing-spark-partitions-with-coalesce-and-repartition-4050c57ad5c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05561f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f00ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangeDF=spark.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817040b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangeDF.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd09a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangeDF.write.csv('/Users/deepakagrawal/Desktop/data', 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "increasedPartitionedDF=rangeDF.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "increasedPartitionedDF.write.csv('/Users/deepakagrawal/Desktop/data', 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc7fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
